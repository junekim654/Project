---
title: "Predict win/lose of each game of March Madness for year 2018"
author: "Team Scorpion - June Kim (jkim654), Hoyin Lau (hlau4), Xiaomei Sun (xsun56), Taiga Hasegawa (taigah2), Leo Franco Soto (francst2)"
date: "5/5/2019"
output: pdf_document
---

# Introduction 

The NCAA Division I Men's Basketball Tournament, also known as NCAA March Madness happens every year in spring. It features 68 college basketball teams from Division I level of the National Collegiate Atheletic Association (NCAA) to determine the national championship. March Madness was first created in 1939 by the National Association of Basketball Coaches and was pitched by Harold Olsen. And currently millions of people in America fill out a bracket to correctly predict the outcome of the entire event.

The format of the tournament are in rounds in the following order (taken from wikipedia.org/wiki/NCAA_Division_I_Men's_Basketball_Tournament):

- The First Four
- The First Round (the Round of 64)
- The Second Round (the Round of 32)
- The Regional Semi-finals (participating teams are known popularly as the "Sweet Sixteen")
- The Regional Finals (participating teams are known commonly as the "Elite Eight")
- The National Semi-finals (participating teams are referred to officially as the "Final Four")
- The National Championship

The motivation behind this project is to correctly predict the outcome of a sports game. The ability to accurately predict the win/loss could help sports betting significantly. We will utilize the basketball game data, like the number of 2 pointers/3 pointers in a given game, to draw out useful information and provide insight on the outcome of each game, which is invaluable to sports bettors and viewers who just want to have a fun bet with friends. The data is from Kaggle Machine Learning Competition hosted by Google Cloud and NCAA 2018. It is a historical data collecting from year 1985 to 2018 (i.e. season 2017-2018, since this year's season is 2018-2019)[1].

In this project, the goal is to...[quantitative goal] by using ..... and determine which model gives the most accurate predictions in year 2018. 

[1] https://www.kaggle.com/c/mens-machine-learning-competition-2018/data

# Data Exploration

The original data from Kaggle Machine Learning Competitions had xx variables with xx observations. For this project, we have cleaned the dataset leaving us with xx variables and xx observations[2].

[2] github/website link to train_X, train_y, test_X, test_y datsets

...about train_X, train_y, test_X, test_y
...print summary stats from train_X, train_y (combined)

The dataset contains information about the regular season before the March Madness. Studies on the performance on regular seasons for the teams presented directly influences whether or not they make it to the March Madness itself. Therefore, we have conducted seasonal analysis and overall performance of each team. 

## Season Analysis 

How teams perform during regular seasons affect their chances of getting into the March Madness. In this part, we have analyzed the seasonal performance of the teams that have historically made it into March Madness. First, we explored the relationship between the location of the game with the percentage of wins. The goal here was to find if percentage of wins are associated with the location. 

```{r,echo=FALSE}
  RegularSeasonDetailedResults = read.csv("PrelimData2018/RegularSeasonDetailedResults_Prelim2018.csv")
  Teams = read.csv("DataFiles/Teams.csv")
  library(plyr)
  library(ggplot2)
  # calculate frequency
  loc_freq = count(RegularSeasonDetailedResults$WLoc)
  
  # calculate percentage and round to 2sf
  loc_freq['percentage'] = 100/sum(loc_freq$freq)*loc_freq$freq
  loc_freq['percentage_r'] <- signif(loc_freq$percentage, digits = 3)
  
  # calculate center of each segment for label
  loc_freq['pos'] <- cumsum(loc_freq$percentage) - loc_freq$percentage/2
  # set levels for segments so can order to match labels
  loc_freq$x <- factor(loc_freq$x, levels = rev(loc_freq$x))
  
  # pie chart
  ggplot(loc_freq, aes(x="", y=percentage_r, fill = x))+
    geom_bar(stat="identity")+coord_polar("y")+
    ggtitle("% of games won at each location")+
    geom_text(aes(y=pos, label=percentage_r))+theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      axis.ticks = element_blank(),
      axis.text = element_blank(),
      panel.border = element_blank(),
      panel.grid = element_blank()
    )
```
From looking at the graph, it is possible to witness 59.5% of the games won were at home while 30.6% were games won away. Neutral locations seem to be the worst options for teams to win, leaving 9.9% of the games won at this location. From this, we can see that locations may have a big impact in the chance of winning. 

## Team Analysis

Teams can be evaluated in terms of (1) goals they score in average or (2) win percentage across seasons. First, we considered the win percentage across the regular season. The questions that could be answered from this analysis are: who are the top 34 teams that frequently wins the game in the regular seasons? Are they ones who make it to the March Madness most frequently? 

From this exploration, it was possible to see that the top 34 teams with the highest % of games won are one of the most frequent teams playing at NCAA March Madness. For instance, Vilanova won in 2018 and it is one of the top 34 teams. Duke, who is on the top 34 teams, is also very strong team, always making it to the Elite Eight most of the seasons. 

```{r, echo = FALSE}
# win freq
team_Wfreq = count(RegularSeasonDetailedResults$WTeamID)
team_Wfreq$x = as.factor(team_Wfreq$x)

# lose freq
team_Lfreq = count(RegularSeasonDetailedResults$LTeamID)
team_Lfreq$x  = as.factor(team_Lfreq$x)

# rename common name to merge
colnames(team_Wfreq)[1] = "TeamID"
colnames(team_Lfreq)[1] = "TeamID"
team_Wfreq = merge(team_Wfreq, Teams, by = "TeamID")
win_freq = merge(team_Wfreq,team_Lfreq, by = "TeamID")
final_frequency = win_freq[-4:-5]
colnames(final_frequency)[2] = "Win"
colnames(final_frequency)[4] = "Lose"

# calculate win percentage
final_frequency["percentage"] = (100 / (final_frequency$Win + final_frequency$Lose)) * final_frequency$Win
final_frequency$TeamID <- as.factor(final_frequency$TeamID)
final_frequency$TeamID <- factor(final_frequency$TeamID, levels = final_frequency$TeamID[order(final_frequency$percentage)])

## Question: What are top 34 teams? 
top.teams = head(final_frequency[order(-final_frequency$percentage),], n=34)
## Question: What are worst 34 teams?
bottom.teams = head(final_frequency[order(final_frequency$percentage),], n=34)

# plot
 ggplot(top.teams, aes(x=TeamName, y=percentage)) +
  ylim(0, 100) +
  ggtitle("Top 34 teams % of games won") +
  geom_bar(stat='identity') +
  xlab("Team Name") + theme(
    axis.text.x = element_text(angle=90, hjust=1)
  )
```

In terms of the number of goals scored, we see a different set of list. It is 

```{r, echo = FALSE}
library(knitr)

Wscores = as.data.frame(RegularSeasonDetailedResults$WTeamID)
colnames(Wscores)[1] = "TeamID"
Wscores["Score"] = RegularSeasonDetailedResults$WScore
Lscores = as.data.frame(RegularSeasonDetailedResults$LTeamID)
colnames(Lscores)[1] = "TeamID"
Lscores["Score"] = RegularSeasonDetailedResults$LScore
AllScores = cbind(Wscores,Lscores)
# calculate team with highest score
AggScores = aggregate(Score ~ TeamID, AllScores,FUN="mean")
AggScores = merge(AggScores, Teams, by = "TeamID")
AggScores$TeamID = as.factor(AggScores$TeamID)
AggScores$TeamID = factor(AggScores$TeamID, levels = AggScores$TeamID[order(AggScores$Score)])
AggScores = AggScores[,-4:-5]

# Top 34 scoring teams
kable(head(AggScores[order(-AggScores$Score), ], n=34))

# Worst 34 scoring teams
kable(head(AggScores[order(AggScores$Score), ], n=34))
```

## Winning Probability by Basketball Statistics

Also, by exploring different basketball statistics that could be engineered further down the analysis, we can figure out which statistics affect the result of the match. Game statistics are those that may contribute to the probability of winning. Points scores in game (pts), number of assists (ast), number of steals (stl) and number of blocks (blk) are some of the examples of "game statistics" in this report. 

For the purpose of exploration, we looked at 13 variables: 
            * pts: points scored in game
            * fgm: field goals made
            * fgm3: 3-point field goals made
            * fga: field goals attempted
            * fga3: 3-point field goals attempted
            * ftm: free throws made
            * fta: free throws attempted
            * ast: number of assists
            * or: number of offensive rebounds
            * to: number of turn-over
            * stl: number of steals
            * blk: number of blocks
            * pf: number of personal fouls

``{r,warning=FALSE,message=FALSE,echo=FALSE}
library(gridExtra)
# pts = points scored in game
# fgm = field goals made
# fgm3 = field goals made (3 points)
# fga = field goals attempted
# fga3 = field goals attempted (3 points)
# ftm = free throws made
# fta = free throws attempted
# ast = assist
# or = offensive rebounds
# to = turn-over
# stl = steal
# blk = block
# pf = personal fouls

# win probability based on fgm
wgfm = as.data.frame(count(RegularSeasonDetailedResults$WFGM))
lgfm = as.data.frame(count(RegularSeasonDetailedResults$LFGM))
fgm_prob = merge(wgfm,lgfm,by=c("x"="x"),all=T)
names(fgm_prob) = c("fgm","win","lose")
fgm_prob["prob"] = probability(fgm_prob)
# win probability based on fgm3
wgfm3 = as.data.frame(count(RegularSeasonDetailedResults$WFGM3))
lgfm3 = as.data.frame(count(RegularSeasonDetailedResults$LFGM3))
fgm3_prob = merge(wgfm3,lgfm3,by=c("x"="x"),all=T)
names(fgm3_prob) = c("fgm3","win","lose")
fgm3_prob["prob"] = probability(fgm3_prob)
# win probability based on fga 
wfga = as.data.frame(count(RegularSeasonDetailedResults$WFGA))
lfga = as.data.frame(count(RegularSeasonDetailedResults$LFGA))
fga_prob = merge(wfga,lfga,by=c("x"="x"),all=T)
names(fga_prob) = c("fga","win","lose")
fga_prob["prob"] = probability(fga_prob)
# win probability based on fga3
wfga3 = as.data.frame(count(RegularSeasonDetailedResults$WFGA3))
lfga3 = as.data.frame(count(RegularSeasonDetailedResults$LFGA3))
fga3_prob = merge(wfga,lfga,by=c("x"="x"),all=T)
names(fga3_prob) = c("fga3","win","lose")
fga3_prob["prob"] = probability(fga3_prob)
# win probability based on ftm
wftm = as.data.frame(count(RegularSeasonDetailedResults$WFTM))
lftm = as.data.frame(count(RegularSeasonDetailedResults$LFTM))
ftm_prob = merge(wftm,lftm,by=c("x"="x"),all=T)
names(ftm_prob) = c("ftm","win","lose")
ftm_prob["prob"] = probability(ftm_prob)
# win probability based on fta
wfta = as.data.frame(count(RegularSeasonDetailedResults$WFTA))
lfta = as.data.frame(count(RegularSeasonDetailedResults$LFTA))
fta_prob = merge(wfta,lfta,by=c("x"="x"),all=T)
names(fta_prob) = c("fta","win","lose")
fta_prob["prob"] = probability(fta_prob)
# win probability based on ast
wast = as.data.frame(count(RegularSeasonDetailedResults$WAst))
last = as.data.frame(count(RegularSeasonDetailedResults$LAst))
ast_prob = merge(wast,last,by=c("x"="x"),all=T)
names(ast_prob) = c("ast","win","lose")
ast_prob["prob"] = probability(ast_prob)
# win probability based on or
wor = as.data.frame(count(RegularSeasonDetailedResults$WOR))
lor  = as.data.frame(count(RegularSeasonDetailedResults$LOR))
or_prob = merge(wor,lor,by=c("x"="x"),all=T)
names(or_prob) = c("or","win","lose")
or_prob["prob"] = probability(or_prob)
# win probability based on to
wdr = as.data.frame(count(RegularSeasonDetailedResults$WDR))
ldr = as.data.frame(count(RegularSeasonDetailedResults$LDR))
dr_prob = merge(wdr,ldr,by=c("x"="x"),all=T)
names(dr_prob) = c("dr","win","lose")
dr_prob["prob"] = probability(dr_prob)
# win probability based on to
wto = as.data.frame(count(RegularSeasonDetailedResults$WTO))
lto = as.data.frame(count(RegularSeasonDetailedResults$LTO))
to_prob = merge(wto,lto,by=c("x"="x"),all=T)
names(to_prob) = c("to","win","lose")
to_prob["prob"] = probability(to_prob)
# win probability based on stl
wstl = as.data.frame(count(RegularSeasonDetailedResults$WStl))
lstl = as.data.frame(count(RegularSeasonDetailedResults$LStl))
stl_prob = merge(wstl,lstl,by=c("x"="x"),all=T)
names(stl_prob) = c("stl","win","lose")
stl_prob["prob"] = probability(stl_prob)
# win probability based on blk
wblk = as.data.frame(count(RegularSeasonDetailedResults$WBlk))
lblk = as.data.frame(count(RegularSeasonDetailedResults$LBlk))
blk_prob = merge(wblk,lblk,by=c("x"="x"),all=T)
names(blk_prob) = c("blk","win","lose")
blk_prob["prob"] = probability(blk_prob)
# win probability based on pf
wpf = as.data.frame(count(RegularSeasonDetailedResults$WPF))
lpf = as.data.frame(count(RegularSeasonDetailedResults$LPF))
pf_prob = merge(wpf,lpf,by=c("x"="x"),all=T)
names(pf_prob) = c("pf","win","lose")
pf_prob["prob"] = probability(pf_prob)

#---graph---#
p1 <- ggplot(Scores_prob, aes(x=score, y=probability)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("Points Scored in Game") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p2 <- ggplot(fgm_prob, aes(x=fgm, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("fgm") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p3 <- ggplot(fga_prob, aes(x=fga, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("fga") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p4 <- ggplot(fgm3_prob, aes(x=fgm3, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("fgm3") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p5 <- ggplot(fga3_prob, aes(x=fga3, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("fga3") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p6 <- ggplot(ftm_prob, aes(x=ftm, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("ftm") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p7 <- ggplot(fta_prob, aes(x=fta, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("fta") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p8 <- ggplot(or_prob, aes(x=or, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("or") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p9 <- ggplot(dr_prob, aes(x=dr, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("dr") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p10 <- ggplot(ast_prob, aes(x=ast, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("ast") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p11 <- ggplot(to_prob, aes(x=to, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("to") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p12 <- ggplot(stl_prob, aes(x=stl, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("stl") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p13 <- ggplot(blk_prob, aes(x=blk, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("blk") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
p14 <- ggplot(pf_prob, aes(x=pf, y=prob)) +
  geom_point(stat='identity') +
  geom_smooth() +
  ylim(0, 1) +
  xlab("pf") + 
  ylab('Win Probability') +
  theme(axis.title.x = element_text(size=11), axis.title.y = element_text(size=11)) +
  theme(aspect.ratio=1)
grid.arrange(p1, p2, p3, p4, p5,p6)
grid.arrange(p7,p8,p9,p10,p11,p12)
grid.arrange(p13,p14)
```
From looking at the graphs, ....


# Data Modeling 

The goal was to find the most accurate prediction model...
Since the dependent variable is binary (i.e. alternating between 0 and 1), models that were considered were: linear discriminant analysis (LDA), ....

...approaches
...why this approach
...which had the best stats (MSE, RMSE, accuracy,etc) - result (model evaluation)

# Conclusion
..resulting conclusions from the modeling (i.e. who has more chance of winning than whom...)
..pitfalls of the analysis
..what needs to be improved

As a group, you will submit files as you would for homework which include a .pdf/.html and .Rmd file. If your data is less than 10MB, you should submit the data too. Otherwise, you should provide a shared link to your actual cleaned R data (using, for example, google drive). Your report must contain the following:

 A breakdown of the points for the final report (with total points of 100). Please note that these are only suggestions and minimal requirements. The instructor and TAs reserve the right for interpreting the rubrics.

> Grading
    (5%) Introduction and literature review:
        Provide enough background to the reader such that they can understand your goal without seeing the data
    (20%) Summary statistics and data visualization:
        Is your summary statistics correct and informative
        Is your visualization of the data correct and informative
    (20%) Use of statistical learning methodology:
        Have you used the appropriate methods for your dataset?
        Have you applied them correctly?
    (20%) Interpretation of statistical learning methodology:
        Do you arrive at the correct conclusions from the analyses you perform?
        Do you correctly interpreting the analyses results in terms of the original scientific problem
    (5%) Conclusion and discussion:
        Objectively summarize your findings and analysis experience
    (10%) Use of R:
        Does your code perform the desired task?
        Is your code readable?
    (10%) Use of R markdown:
        Are you properly utilizing R markdown to have a clean report?
        Is irrelevant code/output hidden?
        Are plots, tables, etc. properly displayed
    (10%) General Organization, Neatness, Readability:
        Is your report easy to read with clear logic
        Is it written in a manner such that a reader does not already need to be familiar with the data?
    **Bonus points* (1 - 10)
    This may be rewarded to project that analyzes an extremely complicated dataset.


